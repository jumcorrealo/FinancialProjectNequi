{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import psycopg2\n",
    "import socket\n",
    "import sys\n",
    "import logging\n",
    "import traceback\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "db_endpoint_RDS = config['database']['host']\n",
    "db_name_RDS = config['database']['database_name']\n",
    "db_user_RDS = config['database']['username']\n",
    "db_password_RDS = config['database']['password']\n",
    "db_port_RDS = int(config['database']['port'])\n",
    "\n",
    "db_endpoint_RSH = config['redshift']['host']\n",
    "db_name_RSH = config['redshift']['database_name']\n",
    "db_user_RSH = config['redshift']['username']\n",
    "db_password_RSH = config['redshift']['password']\n",
    "db_port_RSH = int(config['redshift']['port'])\n",
    "\n",
    "def connect_to_RDS():\n",
    "    conn_rds = psycopg2.connect(\n",
    "            host=db_endpoint_RDS,\n",
    "            port = db_port_RDS,\n",
    "            database = db_name_RDS,\n",
    "            user=db_user_RDS,\n",
    "            password=db_password_RDS\n",
    "        )\n",
    "    return conn_rds\n",
    "\n",
    "def connection_to_RedShift():\n",
    "\n",
    "    conn_rsh = psycopg2.connect(\n",
    "            host=db_endpoint_RSH,\n",
    "            port = db_port_RSH,\n",
    "            database = db_name_RSH,\n",
    "            user=db_user_RSH,\n",
    "            password=db_password_RSH\n",
    "        )\n",
    "    \n",
    "    return conn_rsh\n",
    "\n",
    "\n",
    "try:    \n",
    "\n",
    "    conn_rds = connect_to_RDS()\n",
    "    cur_rds = conn_rds.cursor()\n",
    "    conn_rsh = connection_to_RedShift()\n",
    "    cur_rsh = conn_rsh.cursor()\n",
    "\n",
    "\n",
    "except (socket.timeout, psycopg2.OperationalError) as e:\n",
    "    if isinstance(e, socket.timeout):\n",
    "        print(\"Error: Connection timed out.\")\n",
    "    else:\n",
    "        print(\"Error during connection:\", e)\n",
    "    sys.exit(1)  # Terminate the program with a non-zero exit code\n",
    "\n",
    "\n",
    "try:\n",
    "    # Obtener los símbolos únicos de tbTradingHistoric\n",
    "    cur_rds.execute(\"SELECT DISTINCT \\\"Symbol\\\" FROM tbTradingHistoric;\")\n",
    "    symbols_tbTradingHistoric = cur_rds.fetchall()\n",
    "    print(\"Symbols fetched from tbTradingHistoric successfully!\")\n",
    "\n",
    "    # Obtener los símbolos únicos de tbDimSymbol\n",
    "    cur_rsh.execute(\"SELECT DISTINCT \\\"Symbol\\\" FROM tbDimSymbol;\")\n",
    "    symbols_tbdimSymbols = cur_rsh.fetchall()\n",
    "    print(\"Symbols fetched from tbDimSymbol successfully!\")\n",
    "\n",
    "    # Lista de comprensión para eliminar los símbolos existentes de symbols_tbTradingHistoric\n",
    "    symbols_tbTradingHistoric = [symbol for symbol in symbols_tbTradingHistoric if symbol not in symbols_tbdimSymbols]\n",
    "\n",
    "    # Consulta de inserción\n",
    "    insert_query = \"INSERT INTO tbDimSymbol (Symbol) VALUES (%s)\"\n",
    "\n",
    "    with conn_rsh.cursor() as cur_rsh:\n",
    "        for symbol in symbols_tbTradingHistoric:\n",
    "            try:\n",
    "                cur_rsh.execute(insert_query, symbol)\n",
    "                print(f\"Inserted symbol '{symbol[0]}' into tbDimSymbol successfully!\")\n",
    "            except psycopg2.Error as e:\n",
    "                print(f\"Error occurred during insertion for symbol '{symbol[0]}':\", e)\n",
    "                conn_rsh.rollback()  # Rollback the transaction in case of an error\n",
    "\n",
    "    conn_rsh.commit()  # Commit all the successful insertions\n",
    "\n",
    "except (socket.timeout, psycopg2.OperationalError) as e:\n",
    "    if isinstance(e, socket.timeout):\n",
    "        print(\"Error: Connection timed out.\")\n",
    "    else:\n",
    "        print(\"Error during connection:\", e)\n",
    "    sys.exit(1)  # Terminate the program with a non-zero exit code\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error occurred during SQL query:\", e)\n",
    "    conn_rsh.rollback()  # Rollback the transaction in case of an error\n",
    "\n",
    "\n",
    "conn_rds.close()\n",
    "conn_rsh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "# loggin config\n",
    "logging.basicConfig(filename='./logETLs/scripts.log', level=logging.ERROR,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "console = logging.StreamHandler()\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "db_endpoint_RDS = config['database']['host']\n",
    "db_name_RDS = config['database']['database_name']\n",
    "db_user_RDS = config['database']['username']\n",
    "db_password_RDS = config['database']['password']\n",
    "db_port_RDS = int(config['database']['port'])\n",
    "\n",
    "db_endpoint_RSH = config['redshift']['host']\n",
    "db_name_RSH = config['redshift']['database_name']\n",
    "db_user_RSH = config['redshift']['username']\n",
    "db_password_RSH = config['redshift']['password']\n",
    "db_port_RSH = int(config['redshift']['port'])\n",
    "\n",
    "def connect_to_RDS():\n",
    "    conn_rds = psycopg2.connect(\n",
    "            host=db_endpoint_RDS,\n",
    "            port = db_port_RDS,\n",
    "            database = db_name_RDS,\n",
    "            user=db_user_RDS,\n",
    "            password=db_password_RDS\n",
    "        )\n",
    "    return conn_rds\n",
    "\n",
    "def connection_to_RedShift():\n",
    "\n",
    "    conn_rsh = psycopg2.connect(\n",
    "            host=db_endpoint_RSH,\n",
    "            port = db_port_RSH,\n",
    "            database = db_name_RSH,\n",
    "            user=db_user_RSH,\n",
    "            password=db_password_RSH\n",
    "        )\n",
    "    \n",
    "    return conn_rsh\n",
    "\n",
    "\n",
    "try:    \n",
    "\n",
    "    conn_rds = connect_to_RDS()\n",
    "    cur_rds = conn_rds.cursor()\n",
    "    conn_rsh = connection_to_RedShift()\n",
    "    cur_rsh = conn_rsh.cursor()\n",
    "\n",
    "\n",
    "except (socket.timeout, psycopg2.OperationalError) as e:\n",
    "    if isinstance(e, socket.timeout):\n",
    "        print(\"Error: Connection timed out.\")\n",
    "    else:\n",
    "        print(\"Error during connection:\", e)\n",
    "        logging.error(traceback.format_exc())\n",
    "    sys.exit(1)  # Terminate the program with a non-zero exit code\n",
    "\n",
    "\n",
    "def get_unique_symbols(cur_rds, cur_rsh):\n",
    "    # Obtener los símbolos únicos de tbTradingHistoric\n",
    "    with cur_rds:\n",
    "        cur_rds.execute(\"SELECT * FROM tbTradingHistoric;\")\n",
    "        columns = [desc[0] for desc in cur_rds.description]\n",
    "        data = cur_rds.fetchall()\n",
    "        df_trading_historic = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    \n",
    "    # Obtener los símbolos únicos de tbDimSymbol\n",
    "    with cur_rsh:\n",
    "        cur_rsh.execute(\"SELECT * FROM tbDimSymbol;\")\n",
    "        columns = [desc[0] for desc in cur_rsh.description]\n",
    "        data = cur_rsh.fetchall()\n",
    "        df_DimSymbols = pd.DataFrame(data, columns=columns)\n",
    "    print(\"Symbols fetched from tbDimSymbol successfully!\")\n",
    "\n",
    "    # Cruza la columna 'symbols' del DataFrame df_trading_historic con la columna 'Symbol' de df_DimSymbols\n",
    "    merged_df = df_trading_historic.merge(df_DimSymbols, left_on='symbols', right_on='Symbol', how='left')\n",
    "\n",
    "    # Reemplaza la columna 'symbols' por la columna 'idsymbols' del DataFrame df_DimSymbols\n",
    "    merged_df['symbols'] = merged_df['idsymbols']\n",
    "\n",
    "    # Elimina la columna 'Symbol' que fue utilizada solo para el cruce (opcional)\n",
    "    merged_df.drop(columns='Symbol', inplace=True)\n",
    "\n",
    "    # Retornar el DataFrame df_trading_historic con los ids seleccionados\n",
    "    df_trading_historic_with_ids = merged_df\n",
    "\n",
    "    return df_trading_historic_with_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols fetched from tbDimSymbol successfully!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Symbol'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11896\\3021753740.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Funcion para traer lista con symbol unica\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcombined_symbols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_unique_symbols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_rds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_rsh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;31m# Convertir el DataFrame en una lista de tuplas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata_to_insert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombined_symbols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11896\\2754750482.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(cur_rds, cur_rsh)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mdf_DimSymbols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Symbols fetched from tbDimSymbol successfully!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;31m# Cruza la columna 'symbols' del DataFrame df_trading_historic con la columna 'Symbol' de df_DimSymbols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_trading_historic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_DimSymbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'symbols'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Symbol'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;31m# Reemplaza la columna 'symbols' por la columna 'idsymbols' del DataFrame df_DimSymbols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'symbols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'idsymbols'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   9839\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9840\u001b[0m     ) -> DataFrame:\n\u001b[0;32m   9841\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9843\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m   9844\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9845\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9846\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m ) -> DataFrame:\n\u001b[1;32m--> 148\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    733\u001b[0m         (\n\u001b[0;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m         \u001b[1;31m# to avoid incompatible dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1199\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1204\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1774\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Symbol'"
     ]
    }
   ],
   "source": [
    "  # Funcion para traer lista con symbol unica\n",
    "combined_symbols = get_unique_symbols(cur_rds, cur_rsh)\n",
    "\n",
    "    # Convertir el DataFrame en una lista de tuplas\n",
    "data_to_insert = combined_symbols.to_records(index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols fetched from tbDimSymbol successfully!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'idsymbols'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'idsymbols'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m merged_df \u001b[39m=\u001b[39m df_trading_historic\u001b[39m.\u001b[39mmerge(df_DimSymbols, left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSymbol\u001b[39m\u001b[39m'\u001b[39m, right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msymbol\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[39m# Reemplaza la columna 'symbols' por la columna 'idsymbols' del DataFrame df_DimSymbols\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m merged_df[\u001b[39m'\u001b[39m\u001b[39mSymbol\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m merged_df[\u001b[39m'\u001b[39;49m\u001b[39midsymbols\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     26\u001b[0m \u001b[39m# Elimina la columna 'Symbol' que fue utilizada solo para el cruce (opcional)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m merged_df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msymbol\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'idsymbols'"
     ]
    }
   ],
   "source": [
    "\n",
    "conn_rds = connect_to_RDS()\n",
    "cur_rds = conn_rds.cursor()\n",
    "conn_rsh = connection_to_RedShift()\n",
    "cur_rsh = conn_rsh.cursor()\n",
    "with cur_rds:\n",
    "    cur_rds.execute(\"SELECT * FROM tbTradingHistoric;\")\n",
    "    columns = [desc[0] for desc in cur_rds.description]\n",
    "    data = cur_rds.fetchall()\n",
    "    df_trading_historic = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    \n",
    "    # Obtener los símbolos únicos de tbDimSymbol\n",
    "with cur_rsh:\n",
    "    cur_rsh.execute(\"SELECT * FROM tbDimSymbol;\")\n",
    "    columns = [desc[0] for desc in cur_rsh.description]\n",
    "    data = cur_rsh.fetchall()\n",
    "    df_DimSymbols = pd.DataFrame(data, columns=columns)\n",
    "print(\"Symbols fetched from tbDimSymbol successfully!\")\n",
    "\n",
    "# Cruza la columna 'symbols' del DataFrame df_trading_historic con la columna 'Symbol' de df_DimSymbols\n",
    "merged_df = df_trading_historic.merge(df_DimSymbols, left_on='Symbol', right_on='symbol', how='left')\n",
    "\n",
    "# Reemplaza la columna 'symbols' por la columna 'idsymbols' del DataFrame df_DimSymbols\n",
    "merged_df['Symbol'] = merged_df['idsymbol']\n",
    "\n",
    "# Elimina la columna 'Symbol' que fue utilizada solo para el cruce (opcional)\n",
    "merged_df.drop(columns='symbol', inplace=True)\n",
    "\n",
    "# Retornar el DataFrame df_trading_historic con los ids seleccionados\n",
    "df_trading_historic_with_ids = merged_df\n",
    "\n",
    "df_trading_historic_with_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruza la columna 'symbols' del DataFrame df_trading_historic con la columna 'Symbol' de df_DimSymbols\n",
    "merged_df = df_trading_historic.merge(df_DimSymbols, left_on='Symbol', right_on='symbol', how='left')\n",
    "\n",
    "# Reemplaza la columna 'symbols' por la columna 'idsymbols' del DataFrame df_DimSymbols\n",
    "merged_df['Symbol'] = merged_df['idsymbol']\n",
    "\n",
    "# Elimina la columna 'Symbol' que fue utilizada solo para el cruce (opcional)\n",
    "merged_df.drop(columns='Symbol', inplace=True)\n",
    "merged_df.drop(columns='symbol', inplace=True)\n",
    "# Retornar el DataFrame df_trading_historic con los ids seleccionados\n",
    "df_trading_historic_with_ids = merged_df\n",
    "df_trading_historic_with_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols fetched from tbDimSymbol successfully!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 123\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39m# Ejecutar la inserción\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m conn_rsh\u001b[39m.\u001b[39mcursor() \u001b[39mas\u001b[39;00m cur_rsh:\n\u001b[1;32m--> 123\u001b[0m     cur_rsh\u001b[39m.\u001b[39;49mexecutemany(insert_query, data_to_insert)\n\u001b[0;32m    125\u001b[0m \u001b[39m# Confirmar la transacción\u001b[39;00m\n\u001b[0;32m    126\u001b[0m conn_rsh\u001b[39m.\u001b[39mcommit()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1264.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m### Codec APIs\u001b[39;00m\n\u001b[0;32m     13\u001b[0m encode \u001b[39m=\u001b[39m codecs\u001b[39m.\u001b[39mutf_8_encode\n\u001b[1;32m---> 15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39minput\u001b[39m, errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39mutf_8_decode(\u001b[39minput\u001b[39m, errors, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mIncrementalEncoder\u001b[39;00m(codecs\u001b[39m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import psycopg2\n",
    "import socket\n",
    "import sys\n",
    "import traceback\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "# loggin config\n",
    "logging.basicConfig(filename='./logETLs/scripts.log', level=logging.ERROR,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "console = logging.StreamHandler()\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "db_endpoint_RDS = config['database']['host']\n",
    "db_name_RDS = config['database']['database_name']\n",
    "db_user_RDS = config['database']['username']\n",
    "db_password_RDS = config['database']['password']\n",
    "db_port_RDS = int(config['database']['port'])\n",
    "\n",
    "db_endpoint_RSH = config['redshift']['host']\n",
    "db_name_RSH = config['redshift']['database_name']\n",
    "db_user_RSH = config['redshift']['username']\n",
    "db_password_RSH = config['redshift']['password']\n",
    "db_port_RSH = int(config['redshift']['port'])\n",
    "\n",
    "def connect_to_RDS():\n",
    "    conn_rds = psycopg2.connect(\n",
    "            host=db_endpoint_RDS,\n",
    "            port = db_port_RDS,\n",
    "            database = db_name_RDS,\n",
    "            user=db_user_RDS,\n",
    "            password=db_password_RDS\n",
    "        )\n",
    "    return conn_rds\n",
    "\n",
    "def connection_to_RedShift():\n",
    "\n",
    "    conn_rsh = psycopg2.connect(\n",
    "            host=db_endpoint_RSH,\n",
    "            port = db_port_RSH,\n",
    "            database = db_name_RSH,\n",
    "            user=db_user_RSH,\n",
    "            password=db_password_RSH\n",
    "        )\n",
    "    \n",
    "    return conn_rsh\n",
    "\n",
    "\n",
    "try:    \n",
    "\n",
    "    conn_rds = connect_to_RDS()\n",
    "    cur_rds = conn_rds.cursor()\n",
    "    conn_rsh = connection_to_RedShift()\n",
    "    cur_rsh = conn_rsh.cursor()\n",
    "\n",
    "\n",
    "except (socket.timeout, psycopg2.OperationalError) as e:\n",
    "    if isinstance(e, socket.timeout):\n",
    "        print(\"Error: Connection timed out.\")\n",
    "    else:\n",
    "        print(\"Error during connection:\", e)\n",
    "        logging.error(traceback.format_exc())\n",
    "    sys.exit(1)  # Terminate the program with a non-zero exit code\n",
    "\n",
    "\n",
    "def get_unique_symbols(cur_rds, cur_rsh):\n",
    "    # Obtener los símbolos únicos de tbTradingHistoric\n",
    "    with cur_rds:\n",
    "        cur_rds.execute(\"SELECT * FROM tbTradingHistoric;\")\n",
    "        columns = [desc[0] for desc in cur_rds.description]\n",
    "        data = cur_rds.fetchall()\n",
    "        df_trading_historic = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    \n",
    "    # Obtener los símbolos únicos de tbDimSymbol\n",
    "    with cur_rsh:\n",
    "        cur_rsh.execute(\"SELECT * FROM tbDimSymbol;\")\n",
    "        columns = [desc[0] for desc in cur_rsh.description]\n",
    "        data = cur_rsh.fetchall()\n",
    "        df_DimSymbols = pd.DataFrame(data, columns=columns)\n",
    "    print(\"Symbols fetched from tbDimSymbol successfully!\")\n",
    "\n",
    "    # Cruza la columna 'symbols' del DataFrame df_trading_historic con la columna 'Symbol' de df_DimSymbols\n",
    "    merged_df = df_trading_historic.merge(df_DimSymbols, left_on='Symbol', right_on='symbol', how='left')\n",
    "\n",
    "    # Reemplaza la columna 'symbols' por la columna 'idsymbols' del DataFrame df_DimSymbols\n",
    "    merged_df['Symbol'] = merged_df['idsymbol']\n",
    "\n",
    "    # Elimina la columna 'Symbol' que fue utilizada solo para el cruce (opcional)\n",
    "    merged_df.drop(columns='symbol', inplace=True)\n",
    "    merged_df.drop(columns='Symbol', inplace=True)\n",
    "\n",
    "    # Retornar el DataFrame df_trading_historic con los ids seleccionados\n",
    "    df_trading_historic_with_ids = merged_df\n",
    "\n",
    "    return df_trading_historic_with_ids\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "    # Funcion para traer lista con symbol unica\n",
    "    combined_symbols = get_unique_symbols(cur_rds, cur_rsh)\n",
    "\n",
    "    # Convertir el DataFrame en una lista de tuplas\n",
    "    data_to_insert = combined_symbols.to_records(index=False)\n",
    "    \n",
    "    data_to_insert = [(str(row[0]), row[1], row[2], row[3], row[4], row[5], int(row[6]), int(row[7])) for row in data_to_insert]\n",
    "\n",
    "    # Consulta de inserción\n",
    "    insert_query = \"INSERT INTO tbTradingHistoric (\\\"Date\\\", \\\"Open\\\", \\\"High\\\", \\\"Low\\\", \\\"Close\\\", \\\"Adj_Close\\\", \\\"Volume\\\", \\\"idSymbol\\\") VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "    combined_symbols.to_sql(\"tbtradinghistoric\",conn_rsh,index=False, if_exists=\"replace\")\n",
    "\n",
    "    '''# Ejecutar la inserción\n",
    "    with conn_rsh.cursor() as cur_rsh:\n",
    "        cur_rsh.executemany(insert_query, data_to_insert)\n",
    "\n",
    "    # Confirmar la transacción\n",
    "    conn_rsh.commit()'''\n",
    "\n",
    "except (socket.timeout, psycopg2.OperationalError) as e:\n",
    "    if isinstance(e, socket.timeout):\n",
    "        print(\"Error: Connection timed out.\")\n",
    "    else:\n",
    "        print(\"Error during connection:\", e)\n",
    "        logging.error(traceback.format_exc())\n",
    "    sys.exit(1)  # Terminate the program with a non-zero exit code\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error occurred during SQL query:\", e)\n",
    "    logging.error(traceback.format_exc())\n",
    "    conn_rsh.rollback()  # Rollback the transaction in case of an error\n",
    "\n",
    "\n",
    "conn_rds.close()\n",
    "conn_rsh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.array([(datetime.date(2023, 1, 3), 151.96000671, 153.13000488, 148.47000122, 150.03999329, 149.51045227, 1414300, 3352),\n",
       "           (datetime.date(2023, 1, 4), 151.6499939 , 153.03999329, 150.24000549, 151.66999817, 151.13470459, 1247400, 3352),\n",
       "           (datetime.date(2023, 1, 5), 150.        , 153.07000732, 148.77000427, 152.11000061, 151.57316589, 1714600, 3352),\n",
       "           ...,\n",
       "           (datetime.date(2023, 7, 26),   9.43999958,   9.76000023,   9.43999958,   9.56999969,   9.56999969,  183200, 4330),\n",
       "           (datetime.date(2023, 7, 27),   9.75      ,  10.19999981,   9.51000023,   9.75      ,   9.75      ,  285100, 4330),\n",
       "           (datetime.date(2023, 7, 28),  10.11999989,  10.44999981,   9.88000011,   9.89000034,   9.89000034,  328000, 4330)],\n",
       "          dtype=[('Date', 'O'), ('Open', '<f8'), ('High', '<f8'), ('Low', '<f8'), ('Close', '<f8'), ('Adj_Close', '<f8'), ('Volume', '<i8'), ('idsymbol', '<i8')])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>idsymbol</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>151.960007</td>\n",
       "      <td>153.130005</td>\n",
       "      <td>148.470001</td>\n",
       "      <td>150.039993</td>\n",
       "      <td>149.510452</td>\n",
       "      <td>1414300</td>\n",
       "      <td>A</td>\n",
       "      <td>3352</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>151.649994</td>\n",
       "      <td>153.039993</td>\n",
       "      <td>150.240005</td>\n",
       "      <td>151.669998</td>\n",
       "      <td>151.134705</td>\n",
       "      <td>1247400</td>\n",
       "      <td>A</td>\n",
       "      <td>3352</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>153.070007</td>\n",
       "      <td>148.770004</td>\n",
       "      <td>152.110001</td>\n",
       "      <td>151.573166</td>\n",
       "      <td>1714600</td>\n",
       "      <td>A</td>\n",
       "      <td>3352</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>154.360001</td>\n",
       "      <td>154.639999</td>\n",
       "      <td>143.009995</td>\n",
       "      <td>147.669998</td>\n",
       "      <td>147.148834</td>\n",
       "      <td>2445000</td>\n",
       "      <td>A</td>\n",
       "      <td>3352</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>149.690002</td>\n",
       "      <td>151.279999</td>\n",
       "      <td>147.199997</td>\n",
       "      <td>147.470001</td>\n",
       "      <td>146.949524</td>\n",
       "      <td>1269600</td>\n",
       "      <td>A</td>\n",
       "      <td>3352</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943130</th>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>9.180000</td>\n",
       "      <td>9.510000</td>\n",
       "      <td>9.180000</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>154000</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>4330</td>\n",
       "      <td>ZYXI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943131</th>\n",
       "      <td>2023-07-25</td>\n",
       "      <td>9.190000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>9.190000</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>153100</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>4330</td>\n",
       "      <td>ZYXI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943132</th>\n",
       "      <td>2023-07-26</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>9.760000</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>9.570000</td>\n",
       "      <td>9.570000</td>\n",
       "      <td>183200</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>4330</td>\n",
       "      <td>ZYXI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943133</th>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>9.510000</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>285100</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>4330</td>\n",
       "      <td>ZYXI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943134</th>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>10.120000</td>\n",
       "      <td>10.450000</td>\n",
       "      <td>9.880000</td>\n",
       "      <td>9.890000</td>\n",
       "      <td>9.890000</td>\n",
       "      <td>328000</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>4330</td>\n",
       "      <td>ZYXI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943135 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date        Open        High         Low       Close  \\\n",
       "0       2023-01-03  151.960007  153.130005  148.470001  150.039993   \n",
       "1       2023-01-04  151.649994  153.039993  150.240005  151.669998   \n",
       "2       2023-01-05  150.000000  153.070007  148.770004  152.110001   \n",
       "3       2023-01-06  154.360001  154.639999  143.009995  147.669998   \n",
       "4       2023-01-09  149.690002  151.279999  147.199997  147.470001   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "943130  2023-07-24    9.180000    9.510000    9.180000    9.250000   \n",
       "943131  2023-07-25    9.190000    9.500000    9.190000    9.440000   \n",
       "943132  2023-07-26    9.440000    9.760000    9.440000    9.570000   \n",
       "943133  2023-07-27    9.750000   10.200000    9.510000    9.750000   \n",
       "943134  2023-07-28   10.120000   10.450000    9.880000    9.890000   \n",
       "\n",
       "         Adj_Close   Volume Symbol  idsymbol symbol  \n",
       "0       149.510452  1414300      A      3352      A  \n",
       "1       151.134705  1247400      A      3352      A  \n",
       "2       151.573166  1714600      A      3352      A  \n",
       "3       147.148834  2445000      A      3352      A  \n",
       "4       146.949524  1269600      A      3352      A  \n",
       "...            ...      ...    ...       ...    ...  \n",
       "943130    9.250000   154000   ZYXI      4330   ZYXI  \n",
       "943131    9.440000   153100   ZYXI      4330   ZYXI  \n",
       "943132    9.570000   183200   ZYXI      4330   ZYXI  \n",
       "943133    9.750000   285100   ZYXI      4330   ZYXI  \n",
       "943134    9.890000   328000   ZYXI      4330   ZYXI  \n",
       "\n",
       "[943135 rows x 10 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
